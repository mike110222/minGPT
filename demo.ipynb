{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cute little demo showing the simplest usage of minGPT. Configured to run fine on Macbook Air in like a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class SortDataset(Dataset):\n",
    "    \"\"\" \n",
    "    Dataset for the Sort problem. E.g. for problem length 6:\n",
    "    Input: 0 0 2 1 0 1 -> Output: 0 0 0 1 1 2\n",
    "    Which will feed into the transformer concatenated as:\n",
    "    input:  0 0 2 1 0 1 0 0 0 1 1\n",
    "    output: I I I I I 0 0 0 1 1 2\n",
    "    where I is \"ignore\", as the transformer is reading the input sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split, length=6, num_digits=3):\n",
    "        assert split in {'train', 'test'}\n",
    "        self.split = split\n",
    "        self.length = length\n",
    "        self.num_digits = num_digits\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 10000 # ...\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return self.num_digits\n",
    "    \n",
    "    def get_block_size(self):\n",
    "        # the length of the sequence that will feed into transformer, \n",
    "        # containing concatenated input and the output, but -1 because\n",
    "        # the transformer starts making predictions at the last input element\n",
    "        return self.length * 2 - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # use rejection sampling to generate an input example from the desired split\n",
    "        while True:\n",
    "            # generate some random integers\n",
    "            inp = torch.randint(self.num_digits, size=(self.length,), dtype=torch.long)\n",
    "            # half of the time let's try to boost the number of examples that \n",
    "            # have a large number of repeats, as this is what the model seems to struggle\n",
    "            # with later in training, and they are kind of rate\n",
    "            if torch.rand(1).item() < 0.5:\n",
    "                if inp.unique().nelement() > self.length // 2:\n",
    "                    # too many unqiue digits, re-sample\n",
    "                    continue\n",
    "            # figure out if this generated example is train or test based on its hash\n",
    "            h = hash(pickle.dumps(inp.tolist()))\n",
    "            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n",
    "            if inp_split == self.split:\n",
    "                break # ok\n",
    "        \n",
    "        # solve the task: i.e. sort\n",
    "        sol = torch.sort(inp)[0] \t# sort returns a tuple of two tensors, the sorted tensor and the position of the elements in the original; \n",
    "\n",
    "        # concatenate the problem specification and the solution\n",
    "        cat = torch.cat((inp, sol), dim=0)\n",
    "\n",
    "        # the inputs to the transformer will be the offset sequence\n",
    "        x = cat[:-1].clone()\n",
    "        y = cat[1:].clone()\n",
    "        # we only want to predict at output locations, mask out the loss at the input locations\n",
    "        y[:self.length-1] = -1\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -1\n",
      "0 -1\n",
      "0 -1\n",
      "1 -1\n",
      "1 -1\n",
      "1 0\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "# print an example instance of the dataset\n",
    "train_dataset = SortDataset('train')\n",
    "test_dataset = SortDataset('test')\n",
    "x, y = train_dataset[0]\n",
    "for a, b in zip(x,y):\n",
    "    print(int(a),int(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.09M\n"
     ]
    }
   ],
   "source": [
    "# create a GPT instance\n",
    "from mingpt.model import GPT\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt-nano'\n",
    "model_config.vocab_size = train_dataset.get_vocab_size()\n",
    "model_config.block_size = train_dataset.get_block_size()\n",
    "model = GPT(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n"
     ]
    }
   ],
   "source": [
    "# create a Trainer object\n",
    "from mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-4 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 2000\n",
    "train_config.num_workers = 0\n",
    "trainer = Trainer(train_config, model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 0.00ms; iter 0: train loss 1.07207\n",
      "iter_dt 13.92ms; iter 100: train loss 0.11113\n",
      "iter_dt 15.82ms; iter 200: train loss 0.06465\n",
      "iter_dt 18.19ms; iter 300: train loss 0.05093\n",
      "iter_dt 13.31ms; iter 400: train loss 0.02231\n",
      "iter_dt 12.76ms; iter 500: train loss 0.00663\n",
      "iter_dt 19.54ms; iter 600: train loss 0.03124\n",
      "iter_dt 12.52ms; iter 700: train loss 0.01977\n",
      "iter_dt 12.06ms; iter 800: train loss 0.05053\n",
      "iter_dt 13.84ms; iter 900: train loss 0.00747\n",
      "iter_dt 12.04ms; iter 1000: train loss 0.00475\n",
      "iter_dt 14.23ms; iter 1100: train loss 0.03746\n",
      "iter_dt 12.46ms; iter 1200: train loss 0.04496\n",
      "iter_dt 12.92ms; iter 1300: train loss 0.00192\n",
      "iter_dt 12.56ms; iter 1400: train loss 0.00070\n",
      "iter_dt 12.57ms; iter 1500: train loss 0.01474\n",
      "iter_dt 12.40ms; iter 1600: train loss 0.00312\n",
      "iter_dt 12.85ms; iter 1700: train loss 0.00503\n",
      "iter_dt 12.43ms; iter 1800: train loss 0.00080\n",
      "iter_dt 23.70ms; iter 1900: train loss 0.01967\n"
     ]
    }
   ],
   "source": [
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's perform some evaluation\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train final score: 5000/5000 = 100.00% correct\n",
      "test final score: 5000/5000 = 100.00% correct\n"
     ]
    }
   ],
   "source": [
    "def eval_split(trainer, split, max_batches):\n",
    "    dataset = {'train':train_dataset, 'test':test_dataset}[split]\n",
    "    n = train_dataset.length # naugy direct access shrug\n",
    "    results = []\n",
    "    mistakes_printed_already = 0\n",
    "    loader = DataLoader(dataset, batch_size=100, num_workers=0, drop_last=False)\n",
    "    for b, (x, y) in enumerate(loader):\n",
    "        x = x.to(trainer.device)\n",
    "        y = y.to(trainer.device)\n",
    "        # isolate the input pattern alone\n",
    "        inp = x[:, :n]\n",
    "        sol = y[:, -n:]\n",
    "        # let the model sample the rest of the sequence\n",
    "        cat = model.generate(inp, n, do_sample=False) # using greedy argmax, not sampling\n",
    "        sol_candidate = cat[:, n:] # isolate the filled in sequence\n",
    "        # compare the predicted sequence to the true sequence\n",
    "        correct = (sol == sol_candidate).all(1).cpu() # Software 1.0 vs. Software 2.0 fight RIGHT on this line haha\n",
    "        for i in range(x.size(0)):\n",
    "            results.append(int(correct[i]))\n",
    "            if not correct[i] and mistakes_printed_already < 3: # only print up to 5 mistakes to get a sense\n",
    "                mistakes_printed_already += 1\n",
    "                print(\"GPT claims that %s sorted is %s but gt is %s\" % (inp[i].tolist(), sol_candidate[i].tolist(), sol[i].tolist()))\n",
    "        if max_batches is not None and b+1 >= max_batches:\n",
    "            break\n",
    "    rt = torch.tensor(results, dtype=torch.float)\n",
    "    print(\"%s final score: %d/%d = %.2f%% correct\" % (split, rt.sum(), len(results), 100*rt.mean()))\n",
    "    return rt.sum()\n",
    "\n",
    "# run a lot of examples from both train and test through the model and verify the output correctness\n",
    "with torch.no_grad():\t#unnecessary as generate already has no_grad decorator;\n",
    "    train_score = eval_split(trainer, 'train', max_batches=50)\n",
    "    test_score  = eval_split(trainer, 'test',  max_batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence  : [[0, 0, 2, 1, 0, 1]]\n",
      "predicted sorted: [[0, 0, 0, 1, 1, 2]]\n",
      "gt sort         : [0, 0, 0, 1, 1, 2]\n",
      "matches         : True\n"
     ]
    }
   ],
   "source": [
    "# let's run a random given sequence through the model as well\n",
    "n = train_dataset.length # naugy direct access shrug\n",
    "inp = torch.tensor([[0, 0, 2, 1, 0, 1]], dtype=torch.long).to(trainer.device)\n",
    "assert inp[0].nelement() == n\n",
    "with torch.no_grad():\n",
    "    cat = model.generate(inp, n, do_sample=False)\n",
    "sol = torch.sort(inp[0])[0]\n",
    "sol_candidate = cat[:, n:]\n",
    "print('input sequence  :', inp.tolist())\n",
    "print('predicted sorted:', sol_candidate.tolist())\n",
    "print('gt sort         :', sol.tolist())\n",
    "print('matches         :', bool((sol == sol_candidate).all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('transformer.wte.weight',\n",
       "              tensor([[-1.7782e-02, -1.0397e-02,  4.3755e-03, -9.4283e-03, -1.5903e-02,\n",
       "                        2.2505e-05, -6.1369e-02,  2.6203e-02,  4.7436e-02,  3.7454e-03,\n",
       "                       -4.1899e-02,  2.6155e-02,  2.2934e-03, -2.4311e-02, -2.1005e-02,\n",
       "                        2.6950e-02,  8.4053e-03,  3.0998e-02,  1.2100e-02, -1.4270e-02,\n",
       "                       -8.1398e-03,  1.7157e-02,  2.5038e-02,  1.5144e-02,  7.6834e-02,\n",
       "                       -3.5189e-02,  1.1483e-03,  6.1134e-04,  1.2080e-02,  1.4078e-02,\n",
       "                        6.2777e-02, -6.0420e-04,  2.4666e-02, -2.3203e-02, -1.3324e-02,\n",
       "                       -4.9718e-02, -2.1225e-02,  4.8994e-02,  2.0825e-02,  1.5686e-02,\n",
       "                        9.4109e-03, -8.2799e-03,  3.2943e-02, -2.9890e-02,  2.6659e-02,\n",
       "                        1.1032e-02, -7.0563e-03, -3.6639e-02],\n",
       "                      [ 1.1626e-03,  6.7442e-02,  1.2697e-02, -9.5651e-03, -5.7280e-04,\n",
       "                        8.6631e-02,  3.0774e-03,  2.3667e-03, -1.4371e-03,  8.8704e-03,\n",
       "                       -1.1568e-02, -2.3102e-02, -1.6133e-02,  7.7018e-02,  2.4715e-02,\n",
       "                       -2.4141e-02, -2.7860e-03,  5.0954e-03,  7.6589e-03, -2.6064e-03,\n",
       "                        3.8423e-02, -2.8884e-02,  1.2675e-02, -1.2123e-01, -1.8587e-02,\n",
       "                        5.3932e-02,  1.6155e-02, -4.7861e-02, -5.1686e-03,  7.1484e-03,\n",
       "                       -3.3372e-02, -5.5077e-03, -4.3635e-02,  2.2484e-02,  2.4239e-02,\n",
       "                        3.0585e-02, -1.0505e-02,  2.8879e-03, -1.8825e-02, -3.9513e-02,\n",
       "                       -6.9356e-03, -2.3616e-02,  6.5347e-03,  1.3114e-02, -5.9260e-03,\n",
       "                       -8.0724e-02,  1.4648e-02,  1.8712e-03],\n",
       "                      [ 5.7196e-02, -2.5442e-02,  1.6672e-02,  7.3518e-02,  5.9596e-02,\n",
       "                       -1.3399e-02,  5.5370e-02, -7.5146e-02, -3.4471e-02, -1.4534e-02,\n",
       "                        8.3057e-02, -1.1263e-02,  4.2254e-02, -2.7387e-02, -7.9277e-03,\n",
       "                       -2.5358e-02, -3.3899e-02, -2.8427e-02,  5.8190e-02,  5.3393e-02,\n",
       "                        3.6093e-02, -3.2021e-02, -3.3265e-02, -1.6902e-02, -3.2500e-02,\n",
       "                        4.2543e-03, -2.8836e-03,  3.8920e-02, -6.9675e-02, -4.4693e-02,\n",
       "                       -4.5131e-03, -2.0099e-02,  1.7498e-03,  5.3782e-02, -2.4912e-04,\n",
       "                        1.8693e-02,  9.0173e-02, -6.1959e-02, -1.2843e-01, -2.9668e-02,\n",
       "                        6.7250e-02,  4.0955e-03, -3.4633e-03,  8.0227e-04, -2.0494e-02,\n",
       "                        1.2284e-02,  4.1727e-02,  1.9442e-02]], device='cuda:0')),\n",
       "             ('transformer.wpe.weight',\n",
       "              tensor([[ 1.2939e-02,  3.1918e-02, -2.8631e-02, -3.1411e-02, -2.5435e-02,\n",
       "                        9.0262e-03, -2.2680e-02,  2.4453e-02,  2.1272e-02,  4.1520e-02,\n",
       "                       -1.9385e-02,  1.1979e-02,  1.6888e-02, -1.4748e-03, -1.4126e-02,\n",
       "                        2.1213e-02, -6.3556e-02, -6.6437e-03, -7.2260e-03,  1.1386e-02,\n",
       "                       -2.5455e-02, -2.1324e-03, -8.2572e-03, -1.6212e-02, -9.2905e-03,\n",
       "                        2.8987e-02,  3.4936e-02,  1.0509e-02, -3.2209e-02,  5.1729e-02,\n",
       "                        6.1704e-03,  2.5289e-02, -4.3464e-02, -3.7209e-02, -5.5766e-03,\n",
       "                       -1.1933e-02,  2.0703e-02,  2.3570e-02,  6.1095e-03,  4.2364e-02,\n",
       "                       -2.6824e-05, -5.7400e-03,  8.1445e-03, -5.0910e-03,  7.1359e-03,\n",
       "                        6.1343e-03,  5.1418e-02, -1.2337e-02],\n",
       "                      [-3.3268e-02, -7.2444e-03, -1.0164e-02, -3.1668e-02,  4.6052e-03,\n",
       "                        1.2493e-02,  1.2139e-02,  8.9321e-03, -1.9171e-02, -8.9186e-03,\n",
       "                        1.0680e-03,  3.2617e-02,  1.4598e-02, -4.6039e-04, -2.7851e-02,\n",
       "                        9.5810e-03, -3.3416e-02,  3.7071e-03, -8.3318e-03, -5.1279e-03,\n",
       "                       -4.8664e-03,  2.3150e-02,  8.9688e-03, -1.4585e-03, -5.0384e-02,\n",
       "                        2.7257e-02,  5.2775e-02, -1.1208e-02,  1.5735e-02,  3.8388e-03,\n",
       "                        9.2393e-03,  2.7534e-02, -1.5995e-02, -3.5181e-02, -1.2100e-02,\n",
       "                       -2.3750e-02,  1.2013e-02,  8.5011e-03,  1.4600e-03,  2.6872e-02,\n",
       "                       -2.5871e-02,  2.5039e-03,  8.8474e-03,  2.2224e-02,  1.9836e-03,\n",
       "                       -3.5748e-03,  4.0062e-02, -2.7793e-03],\n",
       "                      [-6.2302e-03,  2.1061e-03, -6.3274e-03, -9.0344e-03, -9.8724e-03,\n",
       "                       -1.1912e-02,  1.8615e-02, -3.9976e-03, -1.5834e-02,  5.5748e-03,\n",
       "                       -2.0627e-02,  7.9477e-03,  9.8771e-03,  7.8777e-03,  1.0030e-02,\n",
       "                        3.9916e-03, -2.2578e-03,  5.6825e-03, -3.3796e-02, -1.8925e-02,\n",
       "                       -3.7900e-02,  1.7192e-02,  8.2769e-03,  1.1504e-03, -6.1139e-02,\n",
       "                        9.7426e-03,  2.5773e-02, -6.3738e-03,  4.9949e-03,  6.9688e-03,\n",
       "                       -3.1677e-02, -2.5837e-03, -2.2117e-02, -4.3414e-02, -3.8738e-03,\n",
       "                       -1.7817e-02,  2.7516e-02,  2.8872e-02,  2.6621e-02,  3.1071e-02,\n",
       "                       -3.0678e-02,  2.5916e-02,  7.5898e-03,  2.5954e-02,  1.7294e-02,\n",
       "                        6.2930e-03, -1.5314e-02, -6.6754e-03],\n",
       "                      [-3.7314e-03,  9.5063e-04, -3.7916e-02, -1.5235e-02,  2.4434e-03,\n",
       "                       -7.8151e-03,  1.3931e-02, -2.6011e-03,  6.8638e-03,  2.4019e-04,\n",
       "                        6.2262e-03,  2.7594e-02, -1.3321e-02, -2.5724e-03,  6.2917e-04,\n",
       "                        1.6639e-02, -2.8894e-03,  1.3483e-02, -3.3768e-02, -1.2153e-02,\n",
       "                       -1.2035e-02,  1.6156e-02, -4.9521e-03,  6.3386e-03, -2.9843e-02,\n",
       "                        2.0378e-02,  3.5219e-02,  9.5769e-03, -4.1782e-03,  9.5034e-03,\n",
       "                       -9.5400e-03,  8.1188e-03, -1.8034e-02, -4.5561e-02,  1.3354e-04,\n",
       "                       -1.8514e-02,  1.4316e-02,  1.2657e-02,  3.4770e-02,  2.7606e-02,\n",
       "                       -7.8521e-03,  1.1522e-02, -7.7944e-03,  4.6567e-03,  8.6308e-03,\n",
       "                        8.4364e-03, -7.4587e-03, -7.3281e-03],\n",
       "                      [-2.2338e-02, -7.9334e-03, -3.1666e-02, -5.8030e-03, -1.0745e-02,\n",
       "                       -2.5940e-03,  2.7030e-02,  9.1918e-03, -9.0651e-03,  7.6888e-03,\n",
       "                       -2.1870e-02,  2.3294e-02, -1.3441e-02,  6.1642e-03,  2.6762e-02,\n",
       "                        6.9001e-03,  6.2304e-03,  9.8083e-03, -4.1197e-02, -1.2364e-02,\n",
       "                       -9.3061e-03,  1.5654e-02, -5.3019e-03,  1.6599e-02, -3.0700e-02,\n",
       "                        2.3836e-02,  3.0155e-02,  3.4209e-03, -2.8435e-03,  1.0673e-02,\n",
       "                       -2.1752e-02, -2.5368e-03, -1.2875e-02, -4.2465e-02, -9.9951e-03,\n",
       "                       -2.0710e-02, -2.4831e-02,  2.6400e-03,  2.9691e-02,  2.6122e-02,\n",
       "                       -2.4633e-02,  1.8460e-02, -1.1543e-02,  3.5415e-03,  1.3553e-02,\n",
       "                        4.1855e-03, -2.4301e-02,  7.0084e-03],\n",
       "                      [-3.7459e-02, -2.8039e-02, -3.9294e-02, -4.9932e-02, -2.6760e-02,\n",
       "                       -2.9349e-02, -6.6892e-03,  4.1396e-02, -2.3739e-02,  8.1223e-02,\n",
       "                        2.0270e-02,  1.3348e-02, -5.5185e-02,  1.5633e-02,  5.3700e-02,\n",
       "                        1.1261e-02,  2.1738e-02, -4.9790e-02, -4.1629e-02, -3.8017e-02,\n",
       "                       -3.0706e-02,  3.5963e-02, -9.0131e-03,  4.2546e-02, -1.7488e-02,\n",
       "                        5.8239e-03,  4.2296e-02,  2.0506e-02,  4.6623e-02,  3.1126e-02,\n",
       "                       -2.2890e-02, -3.6293e-02, -1.7526e-02, -2.7648e-02, -2.9942e-02,\n",
       "                        2.3037e-02, -4.1849e-02, -2.1525e-02,  2.7356e-02,  2.6756e-02,\n",
       "                       -6.7871e-02,  2.4002e-02, -4.5872e-02,  1.6953e-02,  8.7558e-03,\n",
       "                        2.8751e-02,  3.6108e-02,  4.2012e-02],\n",
       "                      [ 1.4008e-02,  8.2463e-03,  6.0388e-03,  7.4931e-03,  4.8330e-02,\n",
       "                       -2.3566e-02, -2.9689e-02, -2.7865e-02, -3.2496e-02, -1.2885e-03,\n",
       "                        5.7397e-02, -4.0367e-02, -3.6119e-02,  6.2174e-02,  2.9917e-02,\n",
       "                       -2.0816e-02,  1.4491e-01, -3.2210e-02,  3.3955e-02,  1.8038e-02,\n",
       "                        9.3151e-03, -9.3587e-03, -3.6179e-02, -1.1604e-02,  8.0380e-02,\n",
       "                       -9.9210e-02, -3.6201e-03,  1.1448e-02,  5.3683e-02, -1.8848e-02,\n",
       "                        5.8095e-02, -1.7723e-02, -1.7509e-02,  2.4447e-02,  1.7387e-02,\n",
       "                        6.2383e-02, -1.6575e-02, -6.4639e-02, -2.8828e-02, -1.8703e-02,\n",
       "                       -3.1111e-03, -1.7667e-02, -6.3606e-02,  4.9207e-02, -2.0485e-02,\n",
       "                       -1.1572e-02,  1.3698e-02,  5.0878e-02],\n",
       "                      [ 1.7595e-02,  2.2979e-02,  3.7241e-02,  2.1895e-03,  1.7015e-01,\n",
       "                        9.0823e-03, -4.8981e-02, -3.5335e-02, -1.7263e-02, -9.1418e-03,\n",
       "                        2.9744e-02, -9.2542e-02,  2.7048e-05,  3.2170e-02,  1.2026e-02,\n",
       "                       -1.0546e-02,  1.9455e-02, -2.2976e-02,  5.0600e-02,  6.8439e-03,\n",
       "                       -1.9939e-03, -2.4415e-02, -7.2067e-03, -3.2826e-02,  1.0085e-01,\n",
       "                       -4.3906e-02, -8.7951e-03, -5.8085e-03,  1.4354e-02, -1.5661e-02,\n",
       "                        7.4187e-02, -6.6647e-03,  8.9369e-03,  2.9283e-02,  2.1293e-02,\n",
       "                        4.4515e-02,  9.1724e-03, -1.8388e-02, -1.9569e-02, -5.4095e-02,\n",
       "                       -1.0326e-03, -1.0971e-02, -1.5216e-02,  7.1422e-02, -4.1875e-02,\n",
       "                       -2.1946e-02,  1.5031e-03,  2.6451e-02],\n",
       "                      [ 1.8972e-02,  2.7558e-02,  1.4940e-01,  6.7912e-03,  7.4425e-02,\n",
       "                        2.7734e-03,  2.4490e-03, -3.8193e-02, -2.2018e-04, -1.1992e-02,\n",
       "                       -4.6244e-04, -1.2885e-01,  1.4835e-02,  1.1126e-02, -9.4468e-03,\n",
       "                       -8.9730e-03,  3.7106e-03, -1.2027e-02,  2.8607e-02,  1.0647e-02,\n",
       "                        1.2796e-01, -1.5467e-02,  2.0658e-02, -4.6412e-02, -1.2742e-02,\n",
       "                       -3.5888e-02, -2.3557e-02, -1.7054e-02,  2.9235e-03, -1.7451e-02,\n",
       "                        3.9398e-02,  8.2474e-03,  7.8956e-02,  2.7640e-02,  3.0254e-02,\n",
       "                        4.3325e-03,  2.5920e-02,  4.9149e-02, -8.5477e-04, -8.3271e-02,\n",
       "                        1.4204e-02, -4.5875e-03, -1.2401e-02,  3.7729e-04, -8.8122e-02,\n",
       "                       -3.2096e-02, -6.4012e-03,  3.9978e-03],\n",
       "                      [ 4.7076e-02,  6.9456e-02,  1.0690e-01,  3.4390e-02, -1.0692e-02,\n",
       "                        4.6595e-02,  1.7045e-02, -3.5992e-02,  6.3609e-02, -2.1013e-02,\n",
       "                       -3.5451e-02, -3.3548e-02,  3.1221e-02, -3.5007e-02, -5.0088e-02,\n",
       "                       -4.5458e-02, -1.2817e-02,  2.0412e-03, -3.1553e-02,  2.6385e-02,\n",
       "                        6.0332e-02, -4.3509e-02, -2.3679e-02, -4.2026e-02, -3.0274e-02,\n",
       "                        3.0303e-02, -7.6805e-02, -5.5254e-02, -1.6363e-02, -3.8781e-02,\n",
       "                        5.4258e-03,  2.6472e-02,  1.1118e-01,  6.1377e-02,  8.1240e-02,\n",
       "                       -6.0468e-03,  3.2729e-02,  6.6318e-02, -6.3356e-05, -3.5294e-02,\n",
       "                        4.4879e-02, -1.9452e-02,  2.6695e-02, -5.2990e-02, -1.5644e-01,\n",
       "                       -4.8165e-02, -3.3919e-02, -6.9339e-02],\n",
       "                      [ 1.1921e-01,  3.6599e-02,  5.1827e-02,  8.4262e-02, -5.9237e-02,\n",
       "                        1.0566e-02,  4.8947e-02, -7.9006e-02,  5.6328e-02, -7.9101e-02,\n",
       "                       -3.2705e-02, -2.6068e-02,  7.4944e-02, -3.6866e-02, -9.1551e-02,\n",
       "                       -4.2775e-02, -5.4853e-02,  9.5429e-02, -4.9350e-02,  1.2228e-01,\n",
       "                       -1.6205e-02, -1.3014e-01, -6.2906e-02, -1.7500e-02, -7.4997e-02,\n",
       "                        6.2348e-02, -1.2690e-01, -7.7525e-02, -6.6982e-02, -1.5308e-01,\n",
       "                       -1.2562e-02,  7.1227e-02,  7.2623e-02,  8.0103e-02,  1.1568e-01,\n",
       "                       -2.1115e-02,  7.5466e-02,  1.1646e-02,  3.2516e-02, -3.6602e-02,\n",
       "                        9.1378e-02, -1.7469e-02,  7.2536e-02, -5.4466e-02, -1.0100e-01,\n",
       "                       -5.0889e-02, -1.2876e-01, -1.2003e-01]], device='cuda:0')),\n",
       "             ('transformer.h.0.ln_1.weight',\n",
       "              tensor([1.0091, 0.9885, 1.0053, 1.0018, 1.0123, 1.0002, 0.9972, 1.0099, 1.0019,\n",
       "                      1.0486, 0.9829, 1.0090, 0.9851, 0.9923, 1.0011, 0.9970, 0.9713, 1.0179,\n",
       "                      0.9683, 1.0215, 0.9834, 1.0244, 0.9805, 0.9845, 0.9963, 0.9851, 1.0005,\n",
       "                      0.9908, 1.0035, 1.0300, 1.0098, 1.0022, 0.9860, 0.9950, 1.0392, 1.0213,\n",
       "                      0.9897, 0.9848, 0.9853, 0.9866, 1.0018, 0.9802, 0.9971, 0.9771, 0.9996,\n",
       "                      1.0086, 0.9864, 1.0073], device='cuda:0')),\n",
       "             ('transformer.h.0.ln_1.bias',\n",
       "              tensor([ 0.0059,  0.0015,  0.0338,  0.0037, -0.0051, -0.0016,  0.0047,  0.0005,\n",
       "                       0.0115, -0.0175, -0.0004, -0.0106,  0.0069, -0.0024,  0.0043, -0.0075,\n",
       "                       0.0300, -0.0043, -0.0161, -0.0007, -0.0035,  0.0004, -0.0018,  0.0075,\n",
       "                      -0.0045, -0.0028, -0.0172, -0.0199,  0.0138, -0.0106,  0.0090,  0.0248,\n",
       "                       0.0110,  0.0095,  0.0070,  0.0104, -0.0065, -0.0026,  0.0087, -0.0028,\n",
       "                       0.0100,  0.0119, -0.0040, -0.0110, -0.0090, -0.0024, -0.0328,  0.0034],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.0.attn.bias',\n",
       "              tensor([[[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]], device='cuda:0')),\n",
       "             ('transformer.h.0.attn.c_attn.weight',\n",
       "              tensor([[-0.0491,  0.0001,  0.0041,  ...,  0.0478,  0.0373,  0.0384],\n",
       "                      [-0.0478, -0.0207, -0.0088,  ...,  0.0490,  0.0110,  0.0156],\n",
       "                      [ 0.0093, -0.0009,  0.0163,  ..., -0.0027, -0.0354, -0.0430],\n",
       "                      ...,\n",
       "                      [ 0.0031,  0.0008,  0.0019,  ..., -0.0128,  0.0173, -0.0073],\n",
       "                      [ 0.0030, -0.0076, -0.0084,  ...,  0.0514,  0.0031, -0.0308],\n",
       "                      [ 0.0040, -0.0005, -0.0083,  ...,  0.0233, -0.0045, -0.0305]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.0.attn.c_attn.bias',\n",
       "              tensor([-1.8249e-02, -1.4908e-02,  1.8398e-02, -1.0561e-02,  6.4608e-02,\n",
       "                      -3.1645e-02,  6.0277e-02, -1.5036e-02,  6.6696e-02, -2.2069e-02,\n",
       "                       5.3481e-02, -1.3681e-02,  3.4008e-02, -5.4668e-03, -7.2324e-03,\n",
       "                      -8.3154e-03, -3.7501e-02,  5.3342e-02,  1.1265e-02, -6.0770e-02,\n",
       "                       4.0424e-02,  3.5751e-02,  1.0538e-02,  2.6417e-02,  3.6218e-02,\n",
       "                      -2.4549e-02, -4.2849e-02,  2.5482e-03, -2.0471e-02,  1.2047e-02,\n",
       "                      -2.3807e-02,  4.4611e-02, -2.8623e-02,  3.5666e-03, -2.3507e-03,\n",
       "                       9.2483e-03, -6.3031e-02,  2.2346e-02,  4.6137e-02,  6.5956e-03,\n",
       "                      -1.9630e-02, -4.6501e-02,  4.6443e-03, -7.1986e-03, -4.0160e-02,\n",
       "                      -5.1794e-02, -7.4623e-02,  1.0604e-02, -1.7174e-04, -1.5268e-04,\n",
       "                       5.6890e-05,  1.4872e-04,  9.4187e-06, -2.2391e-04, -9.1988e-05,\n",
       "                      -1.7682e-04, -1.1125e-04,  7.8450e-05, -5.6981e-04, -2.2626e-04,\n",
       "                      -1.5944e-04, -5.9339e-05, -8.2857e-05, -1.5143e-04,  2.6423e-04,\n",
       "                      -3.4088e-04,  1.5972e-04,  4.2215e-04, -5.5565e-05,  2.5518e-04,\n",
       "                      -2.8263e-04,  2.8950e-04,  1.1327e-04,  1.0250e-04,  2.5407e-04,\n",
       "                       3.0455e-04, -2.7667e-04, -5.1760e-05, -2.9091e-04,  3.6370e-04,\n",
       "                       9.8793e-05,  2.0977e-05,  2.4544e-05,  1.3075e-04,  1.0159e-04,\n",
       "                      -7.3802e-05,  7.6249e-04,  2.0469e-04,  4.1692e-06, -9.9695e-05,\n",
       "                       9.2349e-05, -1.0416e-04, -1.7516e-05, -6.9649e-05,  7.3564e-05,\n",
       "                       1.1656e-04,  1.7785e-03, -1.4159e-03, -3.3586e-03, -8.8873e-03,\n",
       "                       2.5017e-03, -9.7090e-03,  7.1416e-03, -1.2243e-03, -1.0884e-03,\n",
       "                       1.2691e-02, -2.9547e-03,  5.1558e-03,  5.1747e-03,  1.6028e-03,\n",
       "                       5.5077e-03,  8.6206e-03, -6.8983e-04, -7.2594e-03,  6.8450e-03,\n",
       "                       2.7808e-03, -2.1098e-03,  3.0757e-06, -1.6856e-03, -6.5340e-03,\n",
       "                       6.2553e-03,  1.2656e-02, -1.8565e-03, -1.1598e-03, -1.0073e-02,\n",
       "                       4.6714e-03, -6.3288e-03, -1.9182e-03,  1.1339e-02, -7.3487e-03,\n",
       "                      -1.3213e-03, -3.2250e-04,  5.6866e-03,  4.1776e-03, -5.0515e-03,\n",
       "                      -2.5138e-03, -4.0016e-03, -7.4142e-03,  1.0806e-02, -1.8989e-03,\n",
       "                      -2.9532e-03,  3.8961e-03, -3.9374e-03, -1.3890e-02], device='cuda:0')),\n",
       "             ('transformer.h.0.attn.c_proj.weight',\n",
       "              tensor([[-5.4484e-04,  1.9292e-03,  5.8217e-03,  ...,  2.0469e-03,\n",
       "                       -3.7363e-02, -4.2245e-03],\n",
       "                      [ 2.1852e-03, -5.8369e-05,  1.9072e-03,  ...,  3.4862e-03,\n",
       "                       -1.7635e-02, -4.9759e-03],\n",
       "                      [-4.2291e-03,  8.8040e-03, -2.4762e-02,  ..., -6.5891e-03,\n",
       "                        4.8372e-03, -5.2773e-03],\n",
       "                      ...,\n",
       "                      [-2.1990e-02, -6.7504e-04,  4.2587e-03,  ..., -8.6704e-03,\n",
       "                        3.6056e-02, -1.4237e-03],\n",
       "                      [-1.2724e-03,  1.0602e-02, -1.4482e-02,  ..., -4.7009e-03,\n",
       "                        1.2060e-02,  5.0912e-03],\n",
       "                      [ 2.9646e-02,  2.1242e-02, -1.2293e-02,  ..., -1.9333e-02,\n",
       "                        2.4016e-02,  1.7262e-02]], device='cuda:0')),\n",
       "             ('transformer.h.0.attn.c_proj.bias',\n",
       "              tensor([ 0.0028,  0.0041,  0.0052, -0.0040,  0.0168, -0.0044, -0.0080,  0.0002,\n",
       "                      -0.0055,  0.0055, -0.0054, -0.0182, -0.0015,  0.0162,  0.0040, -0.0073,\n",
       "                       0.0140, -0.0038,  0.0157, -0.0023,  0.0149, -0.0004,  0.0040, -0.0080,\n",
       "                       0.0138,  0.0005, -0.0002, -0.0056,  0.0007, -0.0005,  0.0001, -0.0085,\n",
       "                       0.0097,  0.0056,  0.0034,  0.0076, -0.0144,  0.0024, -0.0013, -0.0046,\n",
       "                       0.0014, -0.0029, -0.0026,  0.0011, -0.0033, -0.0036,  0.0037, -0.0054],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.0.ln_2.weight',\n",
       "              tensor([1.0225, 1.0254, 0.9726, 1.0166, 0.9220, 0.9965, 0.9690, 1.0303, 1.0014,\n",
       "                      1.0436, 1.0475, 0.9844, 1.0183, 1.0353, 1.0226, 1.0025, 0.9893, 1.0376,\n",
       "                      0.9920, 1.0221, 0.9532, 1.0024, 0.9908, 1.0231, 0.9156, 0.9818, 1.0087,\n",
       "                      1.0173, 0.9866, 1.0179, 0.9352, 1.0067, 0.9614, 1.0294, 1.0069, 1.0070,\n",
       "                      1.0194, 1.0131, 1.0370, 0.9908, 1.0205, 0.9635, 0.9950, 0.9009, 1.0020,\n",
       "                      1.0294, 1.0217, 1.0163], device='cuda:0')),\n",
       "             ('transformer.h.0.ln_2.bias',\n",
       "              tensor([ 0.0037,  0.0010, -0.0143,  0.0027, -0.0359, -0.0029,  0.0144,  0.0033,\n",
       "                      -0.0067,  0.0033, -0.0042,  0.0175,  0.0051,  0.0042,  0.0022,  0.0011,\n",
       "                      -0.0116,  0.0036, -0.0144,  0.0034, -0.0105, -0.0015, -0.0086,  0.0093,\n",
       "                      -0.0549,  0.0154,  0.0023,  0.0029, -0.0048, -0.0009, -0.0427,  0.0075,\n",
       "                      -0.0055,  0.0005, -0.0047, -0.0052,  0.0043, -0.0089,  0.0023,  0.0220,\n",
       "                       0.0002,  0.0203,  0.0064,  0.0031,  0.0089, -0.0003, -0.0013,  0.0052],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.0.mlp.c_fc.weight',\n",
       "              tensor([[ 0.0256, -0.0144, -0.0178,  ...,  0.0109,  0.0023,  0.0087],\n",
       "                      [ 0.0778,  0.0056, -0.0307,  ..., -0.0175, -0.0611, -0.0316],\n",
       "                      [ 0.0306,  0.0072, -0.0396,  ...,  0.0040, -0.0271,  0.0065],\n",
       "                      ...,\n",
       "                      [-0.0153,  0.0180, -0.0005,  ...,  0.0120, -0.0184,  0.0015],\n",
       "                      [-0.0079, -0.0016, -0.0131,  ..., -0.0357, -0.0448,  0.0604],\n",
       "                      [ 0.0109, -0.0268,  0.0172,  ...,  0.0033, -0.0225, -0.0248]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.0.mlp.c_fc.bias',\n",
       "              tensor([-1.2608e-02,  7.4363e-03, -6.5000e-03, -6.5325e-03, -5.4121e-03,\n",
       "                       5.6408e-03,  8.0264e-03,  2.2354e-03, -1.1004e-02, -1.2144e-02,\n",
       "                      -5.2594e-03, -1.1331e-02, -6.2007e-03, -1.2544e-02,  9.6234e-05,\n",
       "                      -3.3383e-03,  5.2966e-04,  5.5992e-03,  1.5039e-03,  3.7765e-03,\n",
       "                      -7.9301e-03, -4.7709e-03, -1.4086e-02, -9.4659e-03, -5.9222e-03,\n",
       "                      -4.5283e-03, -2.2895e-03, -2.6504e-03,  4.3709e-03,  1.7260e-02,\n",
       "                       5.2346e-03, -2.0808e-02,  2.9674e-03, -1.1976e-02,  2.2225e-03,\n",
       "                       3.3327e-03, -9.3694e-03, -1.2477e-02, -5.3015e-03,  2.2426e-03,\n",
       "                      -4.1900e-03, -1.3446e-02, -2.8520e-02, -1.1346e-02, -1.4068e-02,\n",
       "                       1.4090e-02, -3.2659e-03, -7.7613e-03,  4.2173e-03, -4.6832e-03,\n",
       "                      -4.9106e-03, -9.5866e-03, -1.6643e-03, -8.6498e-03, -5.5375e-03,\n",
       "                       2.9952e-03, -2.0541e-02,  1.1338e-02, -3.7882e-04, -3.0359e-04,\n",
       "                       1.0979e-02, -1.3330e-02,  3.2467e-03,  4.5067e-03,  8.8587e-03,\n",
       "                      -8.4115e-03,  6.9012e-04,  6.6677e-03, -3.5733e-03, -7.7497e-03,\n",
       "                       1.4556e-03, -7.8656e-03,  5.4848e-03,  8.9823e-03, -1.3715e-02,\n",
       "                       4.9220e-03, -1.3868e-02,  3.5619e-03, -1.2788e-02, -9.1321e-03,\n",
       "                      -9.5992e-03, -1.9725e-02,  6.6614e-03, -4.1148e-03, -2.0536e-04,\n",
       "                       8.6164e-04, -9.0767e-03,  5.3782e-05,  1.9195e-03, -1.4894e-02,\n",
       "                      -9.8460e-03,  6.2421e-03,  3.0029e-03, -6.9156e-03, -3.2678e-03,\n",
       "                       1.1723e-02,  2.4386e-03,  8.3435e-03, -4.7832e-03, -1.1980e-02,\n",
       "                       3.7388e-03, -4.4026e-03,  2.3135e-03,  9.8705e-04, -1.2084e-02,\n",
       "                      -1.6130e-02, -2.5546e-03, -7.0430e-04,  8.3212e-03,  1.3703e-03,\n",
       "                       6.7384e-03, -1.5911e-03, -6.3094e-03, -1.7366e-02,  1.1662e-03,\n",
       "                      -8.1733e-03, -5.8628e-03, -2.2036e-03, -1.0729e-02, -9.8763e-03,\n",
       "                      -4.4889e-03,  7.3307e-03, -1.8889e-03, -2.1222e-03, -1.6444e-02,\n",
       "                       3.2839e-03, -3.9417e-03,  5.5902e-03, -6.8900e-03, -1.0911e-02,\n",
       "                       2.2455e-03, -7.9349e-03, -3.6399e-03, -2.2057e-03, -1.2871e-02,\n",
       "                      -3.6997e-03,  1.3142e-03,  2.7718e-03,  1.6078e-03,  3.5089e-03,\n",
       "                      -7.8392e-03, -2.6538e-03,  4.7603e-04, -5.8865e-03, -5.2036e-03,\n",
       "                      -4.5530e-03, -1.4884e-02, -1.8075e-02, -1.5068e-02, -1.2572e-02,\n",
       "                      -8.2233e-03, -2.5600e-03,  1.0404e-02,  1.4881e-03,  8.1530e-03,\n",
       "                      -7.0348e-03, -3.8218e-03, -2.4613e-03, -5.8649e-03, -7.5234e-03,\n",
       "                      -7.0029e-04, -8.9362e-03, -9.5393e-03, -2.7682e-03, -8.0536e-04,\n",
       "                      -9.2117e-03, -8.9389e-03,  1.0028e-02, -3.9009e-03, -3.5983e-03,\n",
       "                       4.2006e-03, -1.5064e-02,  1.2499e-03, -3.3148e-03,  1.1479e-02,\n",
       "                       4.4602e-03, -2.0777e-03, -8.6306e-03, -1.1190e-02, -5.5181e-03,\n",
       "                      -4.9598e-03, -8.2562e-03,  1.4330e-03,  3.2641e-03, -2.7733e-03,\n",
       "                      -5.7142e-03,  1.4223e-03, -2.3942e-03, -7.7403e-03, -5.4688e-04,\n",
       "                      -1.0006e-02,  1.9791e-03], device='cuda:0')),\n",
       "             ('transformer.h.0.mlp.c_proj.weight',\n",
       "              tensor([[-6.8299e-03,  1.4487e-02,  2.0654e-03,  ...,  8.3050e-03,\n",
       "                        1.2332e-02,  7.8224e-03],\n",
       "                      [ 2.9214e-03,  3.2929e-02,  1.0778e-02,  ..., -2.2700e-03,\n",
       "                        6.9058e-03,  1.5891e-02],\n",
       "                      [ 1.2818e-02,  1.6770e-02,  3.9038e-03,  ..., -7.4939e-03,\n",
       "                        2.9161e-02, -5.1777e-03],\n",
       "                      ...,\n",
       "                      [-6.0264e-03,  5.7912e-02,  2.3919e-02,  ...,  1.5021e-02,\n",
       "                        3.8983e-03,  1.7031e-02],\n",
       "                      [ 1.3263e-02, -2.8930e-02, -1.9447e-02,  ...,  5.0642e-03,\n",
       "                        1.1667e-02,  7.2770e-03],\n",
       "                      [-6.5836e-05, -4.1048e-02, -1.5701e-03,  ..., -7.5661e-03,\n",
       "                       -9.9484e-03, -3.3555e-03]], device='cuda:0')),\n",
       "             ('transformer.h.0.mlp.c_proj.bias',\n",
       "              tensor([-0.0019, -0.0027,  0.0002, -0.0120,  0.0158,  0.0020, -0.0120,  0.0019,\n",
       "                       0.0149,  0.0107, -0.0076, -0.0102, -0.0115, -0.0051,  0.0104,  0.0049,\n",
       "                       0.0144,  0.0057,  0.0196, -0.0125, -0.0057,  0.0135,  0.0095, -0.0047,\n",
       "                       0.0066,  0.0024, -0.0084, -0.0037,  0.0082, -0.0002,  0.0083, -0.0129,\n",
       "                       0.0091, -0.0122,  0.0143, -0.0033, -0.0073,  0.0051,  0.0032, -0.0003,\n",
       "                      -0.0095, -0.0062, -0.0135,  0.0029,  0.0046,  0.0043,  0.0040, -0.0073],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.1.ln_1.weight',\n",
       "              tensor([1.0097, 0.9976, 1.0080, 1.0001, 1.0221, 0.9934, 0.9895, 1.0153, 0.9536,\n",
       "                      1.0026, 1.0019, 1.0049, 0.9540, 0.9623, 1.0091, 0.9864, 0.9882, 1.0243,\n",
       "                      0.9965, 0.9876, 0.9732, 0.9862, 0.9997, 1.0001, 0.9894, 0.9861, 0.9955,\n",
       "                      0.9831, 0.9885, 0.9918, 0.9996, 0.9808, 0.9663, 1.0085, 0.9994, 0.9896,\n",
       "                      0.9965, 0.9930, 0.9943, 1.0137, 0.9872, 0.9969, 0.9955, 0.9974, 0.9921,\n",
       "                      1.0021, 0.9760, 1.0058], device='cuda:0')),\n",
       "             ('transformer.h.1.ln_1.bias',\n",
       "              tensor([-1.5955e-05, -1.2022e-02, -7.0598e-03, -1.2393e-03, -2.5895e-03,\n",
       "                       9.4741e-03,  5.1033e-03,  4.6907e-03, -3.3177e-02,  4.3219e-03,\n",
       "                      -1.2740e-03,  5.8967e-03,  3.6599e-02, -1.1735e-02,  4.7771e-03,\n",
       "                       4.4206e-03, -1.4818e-03,  4.9714e-03,  4.0671e-03,  1.4064e-02,\n",
       "                      -3.9595e-02,  2.7634e-03,  7.2889e-03,  9.3254e-04, -5.5361e-03,\n",
       "                       1.1443e-02,  3.8889e-03,  8.3291e-03, -2.7448e-04,  1.5981e-03,\n",
       "                       1.7286e-03, -2.6240e-03,  7.2022e-03, -8.0355e-03, -3.8371e-03,\n",
       "                      -1.5488e-02,  3.2579e-03,  3.7868e-04,  1.3872e-02, -2.9000e-04,\n",
       "                       7.5937e-03, -9.3123e-03,  1.0459e-03,  1.3191e-03,  3.6112e-04,\n",
       "                      -9.6618e-04, -4.8328e-03, -7.6681e-03], device='cuda:0')),\n",
       "             ('transformer.h.1.attn.bias',\n",
       "              tensor([[[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]], device='cuda:0')),\n",
       "             ('transformer.h.1.attn.c_attn.weight',\n",
       "              tensor([[ 0.0157, -0.0178, -0.0419,  ...,  0.0104, -0.0174, -0.0214],\n",
       "                      [-0.0150, -0.0336,  0.0025,  ..., -0.0009,  0.0708,  0.0321],\n",
       "                      [-0.0212,  0.0117,  0.0148,  ...,  0.0036,  0.0327, -0.0065],\n",
       "                      ...,\n",
       "                      [ 0.0295,  0.0180,  0.0402,  ...,  0.0205, -0.0081,  0.0193],\n",
       "                      [-0.0315, -0.0222,  0.0452,  ...,  0.0376, -0.0202, -0.0178],\n",
       "                      [-0.0049,  0.0233,  0.0217,  ...,  0.0450,  0.0206,  0.0053]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.1.attn.c_attn.bias',\n",
       "              tensor([-1.1482e-02,  7.7748e-03,  2.3801e-02, -2.0009e-02, -1.2443e-02,\n",
       "                       4.1051e-03,  3.6010e-03, -1.7950e-02, -1.1744e-02, -6.8092e-03,\n",
       "                      -1.5481e-02, -1.3304e-02,  1.4321e-02, -7.8204e-03, -1.5159e-02,\n",
       "                       1.1758e-03,  1.5037e-02,  3.6460e-03,  1.2995e-02,  2.9854e-03,\n",
       "                       1.0746e-02,  9.2107e-03,  2.1223e-03,  2.9438e-02,  1.7699e-02,\n",
       "                       7.9074e-03,  1.2148e-02,  1.4112e-02, -9.8237e-03, -1.3468e-02,\n",
       "                      -1.3761e-02,  4.8195e-03, -2.1692e-02,  1.4339e-02, -3.0827e-02,\n",
       "                       1.7160e-02,  2.1883e-02, -7.2530e-03, -1.2299e-02,  1.6092e-02,\n",
       "                      -1.2494e-02,  1.8165e-02, -5.5445e-03, -2.2032e-02,  1.5885e-02,\n",
       "                       9.0729e-03,  1.9245e-02,  2.9086e-02, -9.5642e-05, -2.1672e-05,\n",
       "                       1.9049e-04, -8.6057e-05,  1.4704e-05,  2.8625e-05,  1.8831e-05,\n",
       "                      -2.5881e-05, -5.2370e-05,  1.7358e-05,  1.0113e-05, -9.9838e-05,\n",
       "                       9.7922e-05, -4.3431e-05,  7.0260e-06,  1.6199e-04,  3.1977e-05,\n",
       "                      -3.3211e-05,  1.6915e-05, -1.5020e-05, -5.7458e-05, -4.1006e-05,\n",
       "                      -5.1055e-05,  5.0326e-05, -4.7406e-05, -6.7981e-06, -4.4960e-05,\n",
       "                      -4.3997e-06,  1.0520e-04,  2.5510e-04,  1.3764e-04,  1.1717e-04,\n",
       "                       7.7863e-05, -5.2167e-05,  1.2592e-04, -4.1345e-05, -6.6983e-05,\n",
       "                       1.1507e-04,  7.1051e-05, -9.2818e-05,  1.5041e-04, -1.2771e-05,\n",
       "                      -3.0417e-04,  1.3971e-05,  2.1948e-05,  1.8397e-04, -7.3325e-05,\n",
       "                      -1.5292e-04,  6.7087e-03, -4.7407e-03,  5.5555e-03, -1.1117e-02,\n",
       "                       5.8931e-04,  6.1971e-03,  8.0510e-03,  7.1548e-03, -8.5432e-03,\n",
       "                       3.3163e-03,  8.6295e-03,  1.2865e-02,  9.5057e-03, -1.0798e-02,\n",
       "                      -4.2372e-03,  1.6203e-04,  1.1670e-02,  7.6365e-03,  1.3666e-02,\n",
       "                      -1.0419e-02, -1.3941e-02,  7.6103e-03,  6.9463e-03, -1.0767e-02,\n",
       "                       1.0067e-02, -3.6987e-03, -7.5404e-03, -1.0024e-02,  1.1515e-02,\n",
       "                       9.9176e-03, -5.9828e-03,  6.7383e-03, -8.1655e-03,  6.7230e-03,\n",
       "                      -9.5027e-03, -7.1856e-03, -4.7433e-03, -7.4414e-03,  5.5101e-03,\n",
       "                       1.4321e-03, -5.6264e-03, -7.0856e-04,  1.9673e-03, -8.8800e-03,\n",
       "                      -1.1852e-02, -1.2759e-02, -4.1621e-03, -8.8552e-03], device='cuda:0')),\n",
       "             ('transformer.h.1.attn.c_proj.weight',\n",
       "              tensor([[ 0.0054,  0.0037, -0.0003,  ...,  0.0067, -0.0325, -0.0047],\n",
       "                      [ 0.0188,  0.0080, -0.0008,  ..., -0.0081, -0.0176, -0.0063],\n",
       "                      [ 0.0201,  0.0025, -0.0099,  ..., -0.0020, -0.0062,  0.0161],\n",
       "                      ...,\n",
       "                      [ 0.0139,  0.0121,  0.0276,  ..., -0.0181, -0.0298, -0.0305],\n",
       "                      [ 0.0002, -0.0090, -0.0011,  ...,  0.0021,  0.0251,  0.0045],\n",
       "                      [-0.0027,  0.0111,  0.0071,  ..., -0.0023,  0.0105, -0.0058]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.1.attn.c_proj.bias',\n",
       "              tensor([ 0.0066, -0.0056,  0.0037, -0.0126,  0.0216, -0.0034, -0.0182, -0.0064,\n",
       "                       0.0344,  0.0108, -0.0223,  0.0065, -0.0099, -0.0166,  0.0033, -0.0068,\n",
       "                       0.0193, -0.0127,  0.0261, -0.0150, -0.0038,  0.0179, -0.0034,  0.0132,\n",
       "                       0.0203, -0.0166, -0.0127, -0.0066,  0.0024,  0.0046,  0.0006, -0.0105,\n",
       "                       0.0094, -0.0138,  0.0171, -0.0006, -0.0183,  0.0071,  0.0106,  0.0058,\n",
       "                      -0.0078, -0.0061, -0.0094,  0.0178,  0.0039,  0.0067, -0.0066, -0.0114],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.1.ln_2.weight',\n",
       "              tensor([1.0243, 1.0004, 1.0137, 1.0445, 1.0028, 1.0101, 1.0171, 1.0178, 1.0154,\n",
       "                      1.0415, 0.9850, 0.9659, 1.0372, 1.0139, 0.9905, 0.9998, 1.0613, 1.0143,\n",
       "                      0.9983, 1.0273, 0.9802, 1.0131, 0.9982, 1.0029, 1.0356, 1.0172, 1.0111,\n",
       "                      1.0269, 1.0262, 1.0074, 1.0010, 1.0598, 1.0114, 1.0212, 0.9971, 1.0389,\n",
       "                      0.9927, 1.0211, 1.0054, 0.9949, 1.0283, 1.0225, 1.0494, 1.0197, 1.0132,\n",
       "                      0.9995, 1.0266, 1.0371], device='cuda:0')),\n",
       "             ('transformer.h.1.ln_2.bias',\n",
       "              tensor([-0.0100, -0.0169, -0.0118,  0.0011, -0.0111, -0.0100,  0.0083,  0.0100,\n",
       "                      -0.0087,  0.0068, -0.0018,  0.0331,  0.0014, -0.0050, -0.0008, -0.0078,\n",
       "                      -0.0006, -0.0048, -0.0002, -0.0043, -0.0101,  0.0037, -0.0111,  0.0208,\n",
       "                       0.0022,  0.0009,  0.0176,  0.0109,  0.0002,  0.0038, -0.0132, -0.0044,\n",
       "                      -0.0078,  0.0011, -0.0335,  0.0124,  0.0125, -0.0095, -0.0064,  0.0175,\n",
       "                      -0.0117,  0.0115, -0.0054,  0.0069,  0.0065,  0.0018,  0.0088,  0.0088],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.1.mlp.c_fc.weight',\n",
       "              tensor([[-0.0944, -0.0211, -0.0402,  ..., -0.0348,  0.0502,  0.0505],\n",
       "                      [ 0.0254,  0.0216,  0.0229,  ...,  0.0200,  0.0028,  0.0076],\n",
       "                      [ 0.0394,  0.0038,  0.0233,  ..., -0.0099, -0.0362, -0.0011],\n",
       "                      ...,\n",
       "                      [-0.0296, -0.0060, -0.0227,  ..., -0.0510,  0.0460,  0.0196],\n",
       "                      [-0.0005,  0.0235,  0.0028,  ...,  0.0072,  0.0207,  0.0187],\n",
       "                      [-0.0133,  0.0134,  0.0354,  ...,  0.0186, -0.0171,  0.0102]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.1.mlp.c_fc.bias',\n",
       "              tensor([ 0.0033, -0.0023, -0.0052, -0.0247, -0.0021,  0.0139, -0.0159, -0.0214,\n",
       "                      -0.0090, -0.0227,  0.0045,  0.0110,  0.0025, -0.0200,  0.0042,  0.0054,\n",
       "                      -0.0093, -0.0073,  0.0039, -0.0249, -0.0189, -0.0101, -0.0170, -0.0228,\n",
       "                      -0.0052, -0.0178,  0.0038, -0.0050,  0.0176,  0.0092, -0.0156, -0.0119,\n",
       "                      -0.0058, -0.0062, -0.0043, -0.0147, -0.0144, -0.0112,  0.0035, -0.0179,\n",
       "                      -0.0222, -0.0221, -0.0199, -0.0045, -0.0218, -0.0154,  0.0025,  0.0111,\n",
       "                      -0.0125, -0.0201, -0.0104, -0.0008, -0.0140,  0.0025, -0.0152, -0.0115,\n",
       "                      -0.0251, -0.0261, -0.0040,  0.0060, -0.0175, -0.0090, -0.0022, -0.0005,\n",
       "                      -0.0088, -0.0026, -0.0088, -0.0162,  0.0033, -0.0168,  0.0050,  0.0047,\n",
       "                      -0.0062, -0.0095, -0.0003, -0.0089, -0.0092, -0.0149, -0.0118,  0.0057,\n",
       "                      -0.0104, -0.0026, -0.0058, -0.0186, -0.0107, -0.0106, -0.0007,  0.0073,\n",
       "                      -0.0007, -0.0009, -0.0015,  0.0111, -0.0040,  0.0008, -0.0169,  0.0095,\n",
       "                      -0.0001, -0.0048, -0.0161,  0.0104,  0.0091, -0.0083, -0.0041, -0.0324,\n",
       "                      -0.0132, -0.0119,  0.0164, -0.0110, -0.0080, -0.0074, -0.0253, -0.0152,\n",
       "                      -0.0142, -0.0165, -0.0088, -0.0026, -0.0133, -0.0157, -0.0047, -0.0049,\n",
       "                      -0.0203,  0.0222, -0.0052, -0.0105, -0.0044,  0.0014, -0.0105, -0.0063,\n",
       "                      -0.0134, -0.0038, -0.0056,  0.0012, -0.0048, -0.0081, -0.0108, -0.0022,\n",
       "                      -0.0105,  0.0069, -0.0140, -0.0233, -0.0077,  0.0014, -0.0157, -0.0053,\n",
       "                      -0.0215, -0.0144, -0.0194, -0.0143,  0.0170, -0.0061,  0.0017, -0.0205,\n",
       "                      -0.0231, -0.0100, -0.0104, -0.0040, -0.0165,  0.0091, -0.0223, -0.0225,\n",
       "                       0.0015,  0.0011,  0.0166, -0.0111, -0.0152, -0.0173, -0.0041,  0.0014,\n",
       "                       0.0010, -0.0063,  0.0101, -0.0095, -0.0247, -0.0033, -0.0109, -0.0166,\n",
       "                      -0.0120, -0.0046, -0.0193, -0.0048, -0.0140, -0.0238, -0.0192, -0.0285,\n",
       "                      -0.0143, -0.0080, -0.0115, -0.0284,  0.0198,  0.0028, -0.0242, -0.0253],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.1.mlp.c_proj.weight',\n",
       "              tensor([[ 0.0096, -0.0189, -0.0066,  ...,  0.0299, -0.0127, -0.0148],\n",
       "                      [-0.0300,  0.0085,  0.0021,  ..., -0.0258,  0.0087, -0.0007],\n",
       "                      [-0.0051, -0.0027, -0.0130,  ..., -0.0107, -0.0015, -0.0026],\n",
       "                      ...,\n",
       "                      [ 0.0065,  0.0052,  0.0189,  ...,  0.0148, -0.0020, -0.0137],\n",
       "                      [ 0.0426, -0.0091,  0.0042,  ..., -0.0012,  0.0110, -0.0116],\n",
       "                      [ 0.0341, -0.0046, -0.0156,  ...,  0.0061,  0.0148, -0.0195]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.1.mlp.c_proj.bias',\n",
       "              tensor([-9.4023e-04, -1.7997e-02, -1.1205e-02, -1.6192e-02, -3.5780e-03,\n",
       "                      -1.1983e-03, -8.9867e-03, -1.6013e-03,  6.7158e-03,  5.5108e-03,\n",
       "                      -1.8525e-02,  7.0906e-03,  1.2389e-03,  1.5491e-03, -1.4556e-02,\n",
       "                      -2.8328e-03,  1.1556e-02,  1.3483e-02,  9.3807e-03, -1.0434e-02,\n",
       "                       3.1203e-05,  1.6003e-02, -3.9404e-03,  1.6461e-02,  7.1488e-03,\n",
       "                       2.9367e-03, -8.6159e-03, -2.6084e-03, -2.8699e-03,  3.1499e-03,\n",
       "                      -2.4181e-03,  1.2665e-03,  3.1551e-03, -1.6080e-02,  2.1020e-03,\n",
       "                      -1.6482e-03,  1.6037e-02, -3.8573e-03,  9.4451e-03,  6.7112e-03,\n",
       "                      -1.7817e-02,  1.6232e-02, -4.3369e-03, -8.4250e-03,  1.5676e-02,\n",
       "                       1.2805e-02, -7.2749e-03, -9.0449e-03], device='cuda:0')),\n",
       "             ('transformer.h.2.ln_1.weight',\n",
       "              tensor([1.0182, 1.0033, 1.0439, 0.9620, 1.0283, 0.9518, 0.9891, 0.9909, 0.9669,\n",
       "                      1.0465, 1.0113, 1.0267, 0.9875, 0.9680, 1.0228, 0.9522, 0.9709, 0.9878,\n",
       "                      0.9826, 0.9342, 0.9347, 0.9784, 0.9667, 1.0067, 1.0185, 0.9991, 1.0080,\n",
       "                      0.9661, 0.9968, 0.9867, 0.9950, 0.9653, 0.9905, 0.9939, 1.0020, 0.9980,\n",
       "                      0.9973, 0.9906, 0.9808, 1.0242, 1.0549, 1.0026, 1.0054, 0.9989, 0.9861,\n",
       "                      1.0354, 0.9593, 0.9790], device='cuda:0')),\n",
       "             ('transformer.h.2.ln_1.bias',\n",
       "              tensor([ 0.0072, -0.0205, -0.0110,  0.0236, -0.0132, -0.0043,  0.0238,  0.0123,\n",
       "                      -0.0193,  0.0075, -0.0050,  0.0191,  0.0225, -0.0031, -0.0223,  0.0143,\n",
       "                      -0.0250,  0.0208,  0.0107,  0.0319, -0.0200,  0.0002, -0.0034,  0.0041,\n",
       "                      -0.0100,  0.0171, -0.0002, -0.0027,  0.0054,  0.0053, -0.0118,  0.0082,\n",
       "                      -0.0067, -0.0048, -0.0141, -0.0042, -0.0191,  0.0033,  0.0160,  0.0168,\n",
       "                      -0.0132,  0.0142,  0.0048, -0.0364, -0.0090,  0.0199, -0.0194,  0.0124],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.2.attn.bias',\n",
       "              tensor([[[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "                        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]], device='cuda:0')),\n",
       "             ('transformer.h.2.attn.c_attn.weight',\n",
       "              tensor([[ 0.0168,  0.0335,  0.0689,  ..., -0.0483,  0.0221, -0.0521],\n",
       "                      [-0.0016,  0.0242,  0.0547,  ..., -0.0198,  0.0507,  0.0318],\n",
       "                      [ 0.0561,  0.0282, -0.0651,  ...,  0.0448, -0.0255, -0.0086],\n",
       "                      ...,\n",
       "                      [ 0.0758, -0.0426, -0.0006,  ..., -0.0305,  0.0292, -0.0305],\n",
       "                      [-0.0040, -0.0027,  0.0174,  ...,  0.0175,  0.0227,  0.0104],\n",
       "                      [ 0.0100, -0.0381, -0.0615,  ...,  0.0290,  0.0317, -0.0058]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.2.attn.c_attn.bias',\n",
       "              tensor([ 3.0609e-02,  2.5845e-02, -2.6704e-02, -2.6878e-02,  3.8573e-02,\n",
       "                       2.6605e-02,  3.4407e-02,  3.5736e-02, -2.2321e-02,  7.8857e-03,\n",
       "                       9.5478e-04,  3.0593e-02, -2.4893e-02,  2.4822e-02,  2.5599e-02,\n",
       "                       3.3503e-02,  1.3838e-03,  5.7933e-03,  1.3918e-03,  1.5410e-02,\n",
       "                      -4.2783e-03,  5.1726e-03, -1.1122e-02, -5.3048e-03,  2.1756e-02,\n",
       "                      -3.2749e-03, -1.4303e-02,  7.6401e-03, -2.0007e-02, -1.5123e-03,\n",
       "                      -1.9415e-02, -8.6512e-03, -1.0529e-02, -2.2462e-02, -1.7333e-02,\n",
       "                      -3.7520e-03,  7.3638e-03,  1.5234e-02,  1.1939e-02,  3.6993e-03,\n",
       "                       4.6398e-03,  2.7582e-02, -3.6788e-02,  5.0621e-04,  3.4215e-02,\n",
       "                      -1.0030e-03,  6.2323e-03,  2.4261e-02,  3.4225e-05,  6.1736e-05,\n",
       "                       5.4301e-06, -1.7001e-05, -7.2363e-05, -5.7453e-05,  9.1014e-05,\n",
       "                      -3.6272e-05,  4.4371e-06,  2.8242e-05,  2.1227e-05,  1.8751e-05,\n",
       "                      -8.9093e-06,  2.4409e-05,  2.0744e-05, -2.1096e-05, -7.2309e-05,\n",
       "                      -3.5933e-05, -5.1104e-05,  1.8989e-05,  1.0808e-04, -1.8234e-05,\n",
       "                      -2.5293e-05, -1.6676e-05,  4.6524e-05, -1.9080e-05, -1.0054e-04,\n",
       "                      -5.7002e-05, -1.2249e-05, -1.3065e-04,  2.6620e-05,  3.4699e-05,\n",
       "                       1.3104e-04, -4.9982e-05,  5.1548e-05, -1.5333e-04,  5.2313e-07,\n",
       "                       1.3036e-05, -1.1477e-05,  1.2466e-05,  6.5693e-05, -2.3150e-05,\n",
       "                      -4.2680e-05, -9.9925e-06,  8.9043e-05, -1.4448e-04, -1.8047e-05,\n",
       "                      -2.1763e-05,  2.7963e-02, -1.4506e-02,  2.5517e-02,  5.0730e-03,\n",
       "                       1.7923e-02,  1.5035e-02,  6.2257e-03, -1.5963e-02,  2.1334e-02,\n",
       "                       5.2881e-05,  7.9681e-04,  4.9976e-03, -5.3980e-03, -2.0230e-02,\n",
       "                      -8.3210e-03,  1.1541e-02,  8.4068e-03, -1.2326e-02, -5.4109e-03,\n",
       "                       2.2739e-02, -1.4372e-02, -1.3733e-02, -2.9250e-03,  1.8294e-02,\n",
       "                       8.8941e-03,  5.8351e-03,  1.3307e-02,  1.1095e-02, -4.1955e-03,\n",
       "                      -5.7995e-03, -1.5074e-02, -3.7061e-03,  1.3358e-02,  7.5242e-03,\n",
       "                       1.9903e-02, -2.1550e-02,  1.8170e-02, -6.0320e-03, -4.2821e-03,\n",
       "                       1.1695e-02, -2.3691e-03,  1.3586e-02, -8.0503e-03, -4.7197e-04,\n",
       "                      -1.7587e-02, -7.7725e-03, -8.5926e-03,  1.9699e-02], device='cuda:0')),\n",
       "             ('transformer.h.2.attn.c_proj.weight',\n",
       "              tensor([[-0.0095,  0.0085, -0.0224,  ...,  0.0190, -0.0011, -0.0097],\n",
       "                      [ 0.0045, -0.0200,  0.0023,  ...,  0.0235,  0.0081,  0.0225],\n",
       "                      [ 0.0075, -0.0120,  0.0113,  ...,  0.0363,  0.0078,  0.0225],\n",
       "                      ...,\n",
       "                      [-0.0179,  0.0472, -0.0232,  ...,  0.0178,  0.0279, -0.0157],\n",
       "                      [-0.0098,  0.0042, -0.0116,  ..., -0.0421, -0.0102,  0.0027],\n",
       "                      [-0.0234,  0.0026,  0.0101,  ..., -0.0508, -0.0048,  0.0018]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.2.attn.c_proj.bias',\n",
       "              tensor([-1.4377e-02,  6.1260e-03,  3.9923e-03, -1.3203e-02,  9.3349e-03,\n",
       "                       1.4016e-03, -5.2768e-03, -1.4604e-02,  1.3782e-03, -3.6970e-02,\n",
       "                      -2.9453e-02, -2.3839e-02, -2.0798e-03,  7.0815e-03,  1.4320e-02,\n",
       "                      -1.6099e-02,  1.7712e-02,  9.9725e-03,  5.4757e-05, -2.9839e-02,\n",
       "                      -7.3261e-03,  5.1574e-03,  1.5098e-03,  8.1703e-03,  1.3942e-02,\n",
       "                      -1.4932e-02, -8.2867e-03, -7.4690e-03, -1.1396e-02, -1.6665e-03,\n",
       "                       1.1432e-03,  9.5954e-04,  1.6367e-02, -1.2445e-02,  6.9470e-03,\n",
       "                       1.9383e-03,  1.7594e-02,  6.1450e-04,  9.2744e-03,  1.5068e-03,\n",
       "                       1.2445e-02,  7.9600e-04, -3.3708e-03, -1.6351e-03,  2.1891e-02,\n",
       "                      -8.7105e-03, -2.7017e-03, -1.2025e-02], device='cuda:0')),\n",
       "             ('transformer.h.2.ln_2.weight',\n",
       "              tensor([1.0156, 1.0179, 1.0328, 1.0201, 1.0129, 1.0281, 1.0225, 1.0166, 1.0110,\n",
       "                      1.0072, 0.9854, 0.9815, 1.0367, 0.9435, 1.0163, 1.0158, 1.0083, 1.0278,\n",
       "                      1.0056, 1.0413, 1.0144, 1.0102, 1.0291, 1.0113, 1.0336, 1.0165, 1.0156,\n",
       "                      1.0491, 1.0242, 1.0157, 1.0270, 1.0367, 1.0316, 1.0042, 1.0129, 1.0249,\n",
       "                      1.0307, 1.0638, 1.0070, 1.0204, 0.9972, 1.0414, 1.0467, 1.0427, 1.0410,\n",
       "                      1.0130, 1.0388, 1.0624], device='cuda:0')),\n",
       "             ('transformer.h.2.ln_2.bias',\n",
       "              tensor([-0.0136, -0.0185, -0.0119,  0.0088, -0.0023, -0.0154,  0.0003,  0.0123,\n",
       "                      -0.0055,  0.0049, -0.0063,  0.0399,  0.0016, -0.0237, -0.0088, -0.0102,\n",
       "                      -0.0032, -0.0102, -0.0054, -0.0028,  0.0009,  0.0041, -0.0201,  0.0093,\n",
       "                       0.0084, -0.0022,  0.0193,  0.0157, -0.0075, -0.0044, -0.0183, -0.0081,\n",
       "                      -0.0060,  0.0026, -0.0107,  0.0157, -0.0010, -0.0225, -0.0192,  0.0169,\n",
       "                      -0.0060,  0.0221, -0.0024,  0.0001,  0.0100,  0.0078,  0.0107,  0.0194],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.2.mlp.c_fc.weight',\n",
       "              tensor([[-6.5294e-03, -4.0575e-02, -1.9343e-02,  ...,  3.4456e-02,\n",
       "                        3.9181e-02, -2.4706e-02],\n",
       "                      [ 1.3026e-02, -2.7267e-02, -2.1752e-02,  ...,  2.5485e-03,\n",
       "                        2.2131e-02,  9.4240e-03],\n",
       "                      [ 4.2884e-03, -1.6979e-02, -2.8050e-02,  ...,  1.2362e-02,\n",
       "                        3.1681e-02,  1.1353e-01],\n",
       "                      ...,\n",
       "                      [ 2.0089e-02,  9.4725e-03, -1.1508e-02,  ...,  2.1122e-02,\n",
       "                       -6.5181e-03,  4.1729e-06],\n",
       "                      [-4.0193e-02, -5.1302e-02, -7.4961e-02,  ..., -4.6911e-02,\n",
       "                        6.1763e-02,  1.1373e-01],\n",
       "                      [ 4.7488e-02, -2.0464e-02,  1.1130e-02,  ..., -3.3766e-03,\n",
       "                        1.1102e-02,  9.3288e-04]], device='cuda:0')),\n",
       "             ('transformer.h.2.mlp.c_fc.bias',\n",
       "              tensor([-1.7803e-02, -1.6082e-02, -5.1215e-03,  6.6657e-03,  3.5232e-03,\n",
       "                      -1.7267e-03, -9.4443e-03, -4.3002e-04, -9.9643e-03, -9.1334e-03,\n",
       "                      -1.9043e-02, -2.0097e-02,  1.5494e-03, -3.5536e-03,  1.2135e-02,\n",
       "                      -3.2785e-03, -4.7416e-03, -8.9409e-04, -3.1381e-03, -8.1932e-04,\n",
       "                      -1.0417e-02,  6.6490e-03, -3.6624e-03, -1.3633e-02, -4.5597e-03,\n",
       "                      -6.1517e-03, -8.4937e-03, -1.7395e-02, -2.2467e-02,  4.9053e-03,\n",
       "                      -5.8525e-03, -1.0722e-02,  9.9130e-03,  7.8936e-03, -1.7260e-03,\n",
       "                      -7.8507e-03, -1.1933e-02,  8.1372e-03, -7.7581e-03, -1.1584e-02,\n",
       "                       7.6541e-04, -1.4723e-02,  4.3003e-03, -8.8316e-03, -2.6903e-03,\n",
       "                      -1.0646e-02, -2.4825e-03,  3.1545e-03, -2.3250e-03, -2.3534e-02,\n",
       "                       1.1460e-02,  4.7544e-03,  3.8772e-03, -1.8475e-04, -1.2290e-02,\n",
       "                       5.0384e-03,  1.4256e-02, -2.0401e-02,  1.3595e-02, -9.1104e-03,\n",
       "                      -4.1715e-02, -1.1469e-02, -3.8387e-03, -1.0553e-02, -1.6532e-02,\n",
       "                      -8.7718e-03,  2.9255e-03, -1.5600e-02, -1.1715e-02, -1.1120e-02,\n",
       "                      -4.6098e-03, -8.6435e-03,  5.0753e-03, -6.1761e-03, -1.8182e-02,\n",
       "                      -1.6363e-02,  2.5918e-02, -4.2786e-03,  2.9613e-03, -3.4286e-03,\n",
       "                       5.7575e-03, -2.6047e-02, -1.6207e-03, -2.1079e-02,  3.9158e-03,\n",
       "                      -4.2234e-04,  9.1496e-03, -1.5733e-02, -7.9851e-03,  6.8907e-05,\n",
       "                       2.9526e-03,  9.6488e-04, -1.0708e-02,  2.8187e-02, -1.3867e-02,\n",
       "                      -1.0707e-02, -1.3988e-02, -2.1509e-02, -6.3842e-03, -2.1024e-02,\n",
       "                      -2.0082e-03, -1.7427e-02, -1.3709e-02, -3.5406e-03, -1.7147e-02,\n",
       "                      -1.0564e-02,  4.5405e-03, -2.1838e-02, -1.6678e-02, -9.1207e-03,\n",
       "                      -1.0671e-02, -1.8920e-02, -2.3279e-02,  3.7631e-03,  7.2251e-03,\n",
       "                      -9.0582e-03,  9.8527e-03, -8.2919e-03, -2.0995e-02, -2.0444e-02,\n",
       "                       8.4436e-03,  6.5579e-03,  6.7036e-03, -9.8005e-03, -2.7751e-02,\n",
       "                       1.9579e-03,  1.5358e-02, -1.5483e-02, -9.9367e-04, -1.5564e-02,\n",
       "                      -2.0185e-02, -4.7275e-03, -4.0268e-02, -7.1177e-03,  4.8213e-03,\n",
       "                      -8.3597e-03, -2.6712e-03,  1.3798e-03, -6.4300e-03, -1.4512e-02,\n",
       "                      -1.4609e-03, -1.8843e-02, -1.4213e-02, -5.5700e-03, -2.6112e-02,\n",
       "                      -2.2013e-02,  3.2706e-03,  3.7619e-02, -1.9368e-02, -1.4637e-02,\n",
       "                      -1.4451e-02, -1.3419e-02, -2.8421e-02, -1.6095e-02, -1.2630e-02,\n",
       "                      -1.8430e-02, -8.6589e-03, -3.1467e-02, -2.2813e-02, -1.0116e-02,\n",
       "                      -1.2465e-02, -1.3895e-03, -1.4977e-02,  3.7828e-03, -2.1005e-02,\n",
       "                      -2.6483e-02, -1.9330e-02,  2.9227e-03, -6.9619e-03, -2.9628e-02,\n",
       "                      -1.2713e-02,  1.5392e-02, -1.6017e-02, -6.7112e-04, -2.5859e-02,\n",
       "                      -1.5200e-02, -2.4208e-02, -1.6451e-03,  5.1669e-03, -1.7467e-02,\n",
       "                      -2.7256e-02, -2.1845e-02, -1.2747e-02, -3.5966e-03, -1.3982e-02,\n",
       "                       2.8962e-03, -1.0557e-03, -2.2299e-03, -2.0815e-02, -1.9891e-02,\n",
       "                       4.1500e-03, -1.6167e-02], device='cuda:0')),\n",
       "             ('transformer.h.2.mlp.c_proj.weight',\n",
       "              tensor([[ 0.0220,  0.0039,  0.0015,  ..., -0.0180,  0.0122, -0.0288],\n",
       "                      [-0.0016,  0.0095, -0.0022,  ..., -0.0138, -0.0188,  0.0168],\n",
       "                      [ 0.0083, -0.0068,  0.0053,  ..., -0.0087, -0.0129, -0.0062],\n",
       "                      ...,\n",
       "                      [ 0.0054,  0.0143, -0.0107,  ..., -0.0289,  0.0030, -0.0060],\n",
       "                      [ 0.0036, -0.0135,  0.0356,  ...,  0.0034,  0.0378,  0.0091],\n",
       "                      [-0.0044, -0.0180,  0.0217,  ...,  0.0050,  0.0617, -0.0094]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.h.2.mlp.c_proj.bias',\n",
       "              tensor([-0.0236,  0.0021,  0.0084, -0.0159, -0.0047, -0.0135, -0.0099,  0.0123,\n",
       "                       0.0038, -0.0414, -0.0346, -0.0245,  0.0072, -0.0001,  0.0262, -0.0074,\n",
       "                      -0.0083,  0.0133,  0.0120, -0.0038, -0.0041, -0.0031, -0.0026, -0.0048,\n",
       "                       0.0235, -0.0046, -0.0039, -0.0102, -0.0203, -0.0029, -0.0009,  0.0121,\n",
       "                       0.0058, -0.0369, -0.0028, -0.0015,  0.0101,  0.0081,  0.0158,  0.0028,\n",
       "                       0.0161,  0.0010, -0.0002, -0.0100,  0.0150, -0.0153, -0.0008, -0.0095],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer.ln_f.weight',\n",
       "              tensor([1.1511, 1.1569, 1.1576, 1.2041, 1.1365, 1.1764, 1.1373, 1.1749, 1.1565,\n",
       "                      1.1817, 1.1252, 1.1513, 1.1711, 1.1558, 1.2009, 1.1769, 1.1550, 1.2194,\n",
       "                      1.1791, 1.1603, 1.1913, 1.1373, 1.1691, 1.1588, 1.1879, 1.1835, 1.1471,\n",
       "                      1.2454, 1.1719, 1.1643, 1.2331, 1.1739, 1.1595, 1.1676, 1.1614, 1.2672,\n",
       "                      1.2346, 1.1767, 1.2258, 1.1597, 1.1726, 1.1674, 1.1898, 1.1772, 1.1800,\n",
       "                      1.1794, 1.2505, 1.2449], device='cuda:0')),\n",
       "             ('transformer.ln_f.bias',\n",
       "              tensor([-0.0298,  0.0087,  0.0102, -0.0253,  0.0116,  0.0057, -0.0235,  0.0241,\n",
       "                       0.0080, -0.0450, -0.0194,  0.0092, -0.0072, -0.0076,  0.0232,  0.0091,\n",
       "                       0.0118, -0.0081,  0.0015, -0.0364, -0.0091,  0.0125,  0.0063,  0.0163,\n",
       "                       0.0229, -0.0234,  0.0254,  0.0084,  0.0059,  0.0110, -0.0077, -0.0267,\n",
       "                      -0.0338, -0.0310, -0.0185,  0.0087,  0.0237, -0.0002, -0.0082, -0.0066,\n",
       "                       0.0209, -0.0070, -0.0303,  0.0165,  0.0283, -0.0282,  0.0102,  0.0107],\n",
       "                     device='cuda:0')),\n",
       "             ('lm_head.weight',\n",
       "              tensor([[-0.0528, -0.1273, -0.1032, -0.0572, -0.0680, -0.1791, -0.1156,  0.0722,\n",
       "                        0.1719, -0.0918, -0.1058,  0.1443,  0.1128, -0.1521,  0.0744, -0.1214,\n",
       "                        0.1237, -0.2386,  0.1817, -0.0983,  0.1320,  0.1401, -0.1594,  0.1668,\n",
       "                        0.0607, -0.0564,  0.1012,  0.2532, -0.1567, -0.0866, -0.2487, -0.1262,\n",
       "                       -0.1087, -0.0895, -0.0105,  0.2410,  0.0684, -0.2163, -0.2204,  0.1238,\n",
       "                        0.0448,  0.1575, -0.0870,  0.1628,  0.1042, -0.1088,  0.2499,  0.2606],\n",
       "                      [-0.0701,  0.1621,  0.1408, -0.0788,  0.1177,  0.1760,  0.0342,  0.1251,\n",
       "                       -0.0883, -0.0942,  0.0560, -0.0769, -0.1478,  0.1242,  0.1104,  0.1833,\n",
       "                       -0.0715,  0.1037, -0.0935, -0.0385, -0.1894, -0.0503,  0.1666, -0.0472,\n",
       "                        0.1121, -0.1024,  0.1139, -0.1185,  0.1700,  0.1647,  0.1248, -0.1236,\n",
       "                       -0.0862, -0.0480, -0.1490, -0.1299,  0.1295,  0.1526,  0.1371, -0.1439,\n",
       "                        0.1173, -0.1618, -0.0883, -0.0379,  0.0791, -0.0915, -0.0918, -0.0751],\n",
       "                      [ 0.1386, -0.1407, -0.1190,  0.2041, -0.1337, -0.0796,  0.1334, -0.1578,\n",
       "                       -0.0653,  0.1540,  0.1203, -0.0738,  0.1501,  0.0843, -0.1962, -0.1447,\n",
       "                       -0.1116,  0.0857, -0.0568,  0.1361,  0.1246, -0.1001, -0.0896, -0.1024,\n",
       "                       -0.1892,  0.2289, -0.1538, -0.0688, -0.1157, -0.1569,  0.0606,  0.1613,\n",
       "                        0.1382,  0.1723,  0.1592, -0.0931, -0.2237,  0.0025,  0.0841,  0.1152,\n",
       "                       -0.1904,  0.1065,  0.1848, -0.1319, -0.1678,  0.1751, -0.0690, -0.0968]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
